#!/bin/bash

# =============================================================================
# INCREMENTAL BACKUP + AWS S3 SYNC - MERN E-COMMERCE
# Backup ch·ªâ c√°c file thay ƒë·ªïi v√† ƒë·∫©y l√™n S3
# =============================================================================

set -e

# ============= C·∫§U H√åNH =============
WEBSITE_DIR="/var/www/mern-ecommerce"
BACKUP_DIR="/var/backups/mern-ecommerce"
INCREMENTAL_DIR="${BACKUP_DIR}/incremental"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_NAME="incremental_backup_${TIMESTAMP}"
LOG_FILE="${BACKUP_DIR}/incremental_backup.log"
SNAPSHOT_FILE="${BACKUP_DIR}/.snapshot"

# AWS S3 Configuration
S3_BUCKET="s3://mern-ecommerce-backup-2024/mern-ecommerce-backups"  # ‚Üê Thay t√™n bucket
AWS_REGION="ap-southeast-1"  # ‚Üê Thay region (Singapore)
AWS_PROFILE="default"  # ‚Üê Thay AWS profile n·∫øu c·∫ßn

# MongoDB Atlas Configuration
MONGO_URI="mongodb+srv://phunghung146_db_user:uvcA1Hyn7HkFmHDo@cluster0.seoz547.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0"
MONGO_DB="test"

# Retention policy
LOCAL_RETENTION_DAYS=7   # Gi·ªØ backup local 7 ng√†y
S3_RETENTION_DAYS=90     # Gi·ªØ backup tr√™n S3 90 ng√†y

# ============= M√ÄU S·∫ÆC =============
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
NC='\033[0m'

# ============= FUNCTIONS =============

log() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

print_status() {
    echo -e "${BLUE}[INFO]${NC} $1"
    log "INFO: $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
    log "SUCCESS: $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
    log "ERROR: $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
    log "WARNING: $1"
}

print_s3() {
    echo -e "${CYAN}[S3]${NC} $1"
    log "S3: $1"
}

# Ki·ªÉm tra quy·ªÅn root
check_root() {
    if [[ $EUID -ne 0 ]]; then
        print_error "Script c·∫ßn ch·∫°y v·ªõi quy·ªÅn root (sudo)"
        exit 1
    fi
}

# Ki·ªÉm tra AWS CLI
check_aws_cli() {
    print_status "Ki·ªÉm tra AWS CLI..."
    
    if ! command -v aws &> /dev/null; then
        print_error "AWS CLI ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t!"
        echo ""
        echo "C√†i ƒë·∫∑t AWS CLI:"
        echo "  curl 'https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip' -o 'awscliv2.zip'"
        echo "  unzip awscliv2.zip"
        echo "  sudo ./aws/install"
        echo ""
        exit 1
    fi
    
    # Ki·ªÉm tra AWS credentials
    if ! aws sts get-caller-identity --profile "$AWS_PROFILE" &>/dev/null; then
        print_error "AWS credentials ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh!"
        echo ""
        echo "C·∫•u h√¨nh AWS:"
        echo "  aws configure --profile $AWS_PROFILE"
        echo ""
        exit 1
    fi
    
    print_success "AWS CLI ƒë√£ s·∫µn s√†ng"
}

# T·∫°o th∆∞ m·ª•c
create_directories() {
    mkdir -p "$BACKUP_DIR"
    mkdir -p "$INCREMENTAL_DIR"
    mkdir -p "${INCREMENTAL_DIR}/temp_${TIMESTAMP}"
    chmod 700 "$BACKUP_DIR"
}

# T√¨m c√°c file ƒë√£ thay ƒë·ªïi k·ªÉ t·ª´ l·∫ßn backup cu·ªëi
find_changed_files() {
    print_status "T√¨m c√°c file ƒë√£ thay ƒë·ªïi..."
    
    local temp_dir="${INCREMENTAL_DIR}/temp_${TIMESTAMP}/website"
    mkdir -p "$temp_dir"
    
    # T·∫°o file snapshot n·∫øu ch∆∞a c√≥ (l·∫ßn ƒë·∫ßu ti√™n)
    if [ ! -f "$SNAPSHOT_FILE" ]; then
        print_warning "L·∫ßn ƒë·∫ßu ti√™n ch·∫°y incremental backup"
        print_status "T·∫°o snapshot ban ƒë·∫ßu..."
        find "$WEBSITE_DIR" -type f -printf "%T@ %p\n" | sort > "$SNAPSHOT_FILE"
        print_success "Snapshot ƒë√£ ƒë∆∞·ª£c t·∫°o"
    fi
    
    # T√¨m files m·ªõi ho·∫∑c ƒë√£ thay ƒë·ªïi
    local changed_files="${INCREMENTAL_DIR}/changed_files_${TIMESTAMP}.txt"
    
    find "$WEBSITE_DIR" -type f \
        -newer "$SNAPSHOT_FILE" \
        ! -path "*/node_modules/*" \
        ! -path "*/.git/*" \
        ! -name "*.log" \
        > "$changed_files"
    
    local file_count=$(wc -l < "$changed_files")
    
    if [ "$file_count" -eq 0 ]; then
        print_warning "Kh√¥ng c√≥ file n√†o thay ƒë·ªïi k·ªÉ t·ª´ l·∫ßn backup cu·ªëi"
        echo "skip" > "${INCREMENTAL_DIR}/.skip_flag"
        return 0
    fi
    
    print_success "T√¨m th·∫•y $file_count file ƒë√£ thay ƒë·ªïi"
    
    # Copy c√°c file ƒë√£ thay ƒë·ªïi v·ªõi c·∫•u tr√∫c th∆∞ m·ª•c
    while IFS= read -r file; do
        # L·∫•y ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi
        local rel_path="${file#$WEBSITE_DIR/}"
        local dest_file="${temp_dir}/${rel_path}"
        local dest_dir=$(dirname "$dest_file")
        
        mkdir -p "$dest_dir"
        cp -p "$file" "$dest_file"
    done < "$changed_files"
    
    print_success "ƒê√£ copy c√°c file thay ƒë·ªïi"
}

# Backup MongoDB incremental (dump to√†n b·ªô v√¨ MongoDB kh√¥ng support incremental native)
backup_mongodb_incremental() {
    print_status "Backup MongoDB database..."
    
    local temp_dir="${INCREMENTAL_DIR}/temp_${TIMESTAMP}/mongodb"
    mkdir -p "$temp_dir"
    
    if command -v mongodump &> /dev/null; then
        mongodump \
            --uri="$MONGO_URI" \
            --db="$MONGO_DB" \
            --out="$temp_dir" \
            --gzip \
            --quiet
        
        print_success "MongoDB backup ho√†n t·∫•t"
    else
        print_warning "mongodump kh√¥ng c√≥, b·ªè qua MongoDB backup"
    fi
}

# Backup configs ƒë√£ thay ƒë·ªïi
backup_changed_configs() {
    print_status "Backup configurations..."
    
    local temp_dir="${INCREMENTAL_DIR}/temp_${TIMESTAMP}/configs"
    mkdir -p "$temp_dir"
    
    # Backup .env n·∫øu thay ƒë·ªïi
    [ -f "${WEBSITE_DIR}/backend/.env" ] && \
        [ "${WEBSITE_DIR}/backend/.env" -nt "$SNAPSHOT_FILE" ] && \
        cp "${WEBSITE_DIR}/backend/.env" "$temp_dir/backend.env"
    
    [ -f "${WEBSITE_DIR}/frontend/.env" ] && \
        [ "${WEBSITE_DIR}/frontend/.env" -nt "$SNAPSHOT_FILE" ] && \
        cp "${WEBSITE_DIR}/frontend/.env" "$temp_dir/frontend.env"
    
    # Backup Nginx config n·∫øu thay ƒë·ªïi
    [ -f "/etc/nginx/sites-available/mern-ecommerce" ] && \
        [ "/etc/nginx/sites-available/mern-ecommerce" -nt "$SNAPSHOT_FILE" ] && \
        cp "/etc/nginx/sites-available/mern-ecommerce" "$temp_dir/"
    
    print_success "Config backup ho√†n t·∫•t"
}

# T·∫°o metadata
create_metadata() {
    local metadata_file="${INCREMENTAL_DIR}/temp_${TIMESTAMP}/BACKUP_INFO.txt"
    
    # ƒê·ªçc th√¥ng tin t·ª´ changed_files
    local changed_files="${INCREMENTAL_DIR}/changed_files_${TIMESTAMP}.txt"
    local file_count=0
    [ -f "$changed_files" ] && file_count=$(wc -l < "$changed_files")
    
    cat > "$metadata_file" << EOF
===========================================
INCREMENTAL BACKUP INFORMATION
===========================================
Backup Date: $(date)
Backup Type: INCREMENTAL
Hostname: $(hostname)
Changed Files: $file_count

===========================================
LAST FULL BACKUP
===========================================
$(stat -c "Last Full: %y" "$SNAPSHOT_FILE" 2>/dev/null || echo "No previous backup")

===========================================
CHANGED FILES LIST
===========================================
$([ -f "$changed_files" ] && cat "$changed_files" | head -20 || echo "No changes")
$([ "$file_count" -gt 20 ] && echo "... and $(($file_count - 20)) more files")

===========================================
SYSTEM STATUS
===========================================
Disk Usage:
$(df -h | grep -E '^/dev/')

Memory:
$(free -h)
EOF
    
    print_success "Metadata created"
}

# N√©n backup
compress_backup() {
    # Ki·ªÉm tra flag skip
    if [ -f "${INCREMENTAL_DIR}/.skip_flag" ]; then
        rm -f "${INCREMENTAL_DIR}/.skip_flag"
        print_warning "B·ªè qua n√©n v√¨ kh√¥ng c√≥ thay ƒë·ªïi"
        return 0
    fi
    
    print_status "N√©n incremental backup..."
    
    local temp_dir="${INCREMENTAL_DIR}/temp_${TIMESTAMP}"
    local compressed_file="${INCREMENTAL_DIR}/${BACKUP_NAME}.tar.gz"
    
    # Hi·ªÉn th·ªã size
    local size_before=$(du -sh "$temp_dir" | cut -f1)
    print_status "Size tr∆∞·ªõc n√©n: $size_before"
    
    # N√©n v·ªõi pigz n·∫øu c√≥
    if command -v pigz &> /dev/null; then
        tar -I pigz -cf "$compressed_file" -C "${INCREMENTAL_DIR}" "temp_${TIMESTAMP}"
    else
        tar -czf "$compressed_file" -C "${INCREMENTAL_DIR}" "temp_${TIMESTAMP}"
    fi
    
    local size_after=$(du -sh "$compressed_file" | cut -f1)
    print_success "Size sau n√©n: $size_after"
    
    # T·∫°o checksum
    sha256sum "$compressed_file" > "${compressed_file}.sha256"
    
    # X√≥a temp
    rm -rf "$temp_dir"
    rm -f "${INCREMENTAL_DIR}/changed_files_${TIMESTAMP}.txt"
    
    print_success "Backup ƒë√£ ƒë∆∞·ª£c n√©n: ${BACKUP_NAME}.tar.gz"
}

# Sync to AWS S3
sync_to_s3() {
    print_s3 "B·∫Øt ƒë·∫ßu sync l√™n AWS S3..."
   
    
    # Upload incremental backups
    print_s3 "Uploading incremental backups..."
    aws s3 sync "$INCREMENTAL_DIR" "$S3_BUCKET/incremental/" \
        --profile "$AWS_PROFILE" \
        --region "$AWS_REGION" \
        --storage-class STANDARD_IA \
        --exclude "temp_*" \
        --exclude ".skip_flag" \
        --exclude "changed_files_*" \
        --exclude ".snapshot" \
        --no-progress
    
    print_success "Incremental backups ƒë√£ upload l√™n S3"
    
    # Upload full backups (n·∫øu c√≥)
    if [ -d "${BACKUP_DIR}" ] && [ "$(ls -A ${BACKUP_DIR}/full_backup_*.tar.gz 2>/dev/null)" ]; then
        print_s3 "Uploading full backups..."
        aws s3 sync "$BACKUP_DIR" "$S3_BUCKET/full/" \
            --profile "$AWS_PROFILE" \
            --region "$AWS_REGION" \
            --storage-class STANDARD_IA \
            --include "full_backup_*.tar.gz*" \
            --exclude "*" \
            --no-progress
        
        print_success "Full backups ƒë√£ upload l√™n S3"
    fi
    
    # Hi·ªÉn th·ªã S3 storage info
    print_s3 "Th√¥ng tin S3 storage:"
    aws s3 ls "$S3_BUCKET/" --recursive --human-readable --summarize \
        --profile "$AWS_PROFILE" | tail -2
}

# Apply lifecycle policy to S3
apply_s3_lifecycle() {
    print_s3 "√Åp d·ª•ng S3 lifecycle policy..."
    
    local bucket_name=$(echo $S3_BUCKET | cut -d'/' -f3)
    local lifecycle_config=$(cat <<EOF
{
    "Rules": [
        {
            "Id": "DeleteOldIncrementalBackups",
            "Status": "Enabled",
            "Prefix": "mern-ecommerce-backups/incremental/",
            "Expiration": {
                "Days": ${S3_RETENTION_DAYS}
            }
        },
        {
            "Id": "TransitionFullBackupsToGlacier",
            "Status": "Enabled",
            "Prefix": "mern-ecommerce-backups/full/",
            "Transitions": [
                {
                    "Days": 30,
                    "StorageClass": "GLACIER"
                }
            ],
            "Expiration": {
                "Days": 365
            }
        }
    ]
}
EOF
)
    
    echo "$lifecycle_config" > /tmp/s3-lifecycle.json
    
    aws s3api put-bucket-lifecycle-configuration \
        --bucket "$bucket_name" \
        --lifecycle-configuration file:///tmp/s3-lifecycle.json \
        --profile "$AWS_PROFILE" 2>/dev/null || print_warning "Kh√¥ng th·ªÉ set lifecycle policy"
    
    rm -f /tmp/s3-lifecycle.json
    
    print_success "Lifecycle policy ƒë√£ ƒë∆∞·ª£c √°p d·ª•ng"
}

# X√≥a backup local c≈©
cleanup_local_backups() {
    print_status "X√≥a backup local c≈© (>$LOCAL_RETENTION_DAYS ng√†y)..."
    
    find "$INCREMENTAL_DIR" -name "incremental_backup_*.tar.gz" -type f -mtime +$LOCAL_RETENTION_DAYS -delete
    find "$INCREMENTAL_DIR" -name "incremental_backup_*.tar.gz.sha256" -type f -mtime +$LOCAL_RETENTION_DAYS -delete
    
    print_success "ƒê√£ x√≥a backup local c≈©"
}

# Update snapshot
update_snapshot() {
    # Ch·ªâ update n·∫øu c√≥ backup th√†nh c√¥ng
    if [ ! -f "${INCREMENTAL_DIR}/.skip_flag" ]; then
        print_status "C·∫≠p nh·∫≠t snapshot..."
        find "$WEBSITE_DIR" -type f -printf "%T@ %p\n" | sort > "$SNAPSHOT_FILE"
        print_success "Snapshot ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t"
    fi
}

# Hi·ªÉn th·ªã b√°o c√°o
show_report() {
    echo ""
    echo -e "${GREEN}=========================================="
    echo "   INCREMENTAL BACKUP HO√ÄN T·∫§T!"
    echo -e "==========================================${NC}"
    echo ""
    echo "üì¶ Local Backup:"
    echo "   Location: $INCREMENTAL_DIR"
    ls -lh "$INCREMENTAL_DIR"/incremental_backup_*.tar.gz 2>/dev/null | tail -3 || echo "   (Kh√¥ng c√≥ backup m·ªõi)"
    echo ""
    echo "‚òÅÔ∏è  S3 Backup:"
    echo "   Bucket: $S3_BUCKET"
    echo "   Region: $AWS_REGION"
    echo ""
    echo "üìä Next Backup:"
    echo "   Ch·ªâ backup c√°c file thay ƒë·ªïi k·ªÉ t·ª´: $(date)"
    echo ""
    echo "üìù Logs: $LOG_FILE"
    echo ""
}

# Main function
main() {
    echo -e "${CYAN}"
    echo "=========================================="
    echo "  INCREMENTAL BACKUP + AWS S3 SYNC"
    echo "=========================================="
    echo -e "${NC}"
    
    local start_time=$(date +%s)
    
    # Checks
    check_root
    check_aws_cli
    create_directories
    
    # Backup process
    find_changed_files
    backup_mongodb_incremental
    backup_changed_configs
    create_metadata
    compress_backup
    
    # S3 sync
    sync_to_s3
    apply_s3_lifecycle
    
    # Cleanup
    cleanup_local_backups
    update_snapshot
    
    # Report
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    
    show_report
    echo "‚è±Ô∏è  Th·ªùi gian: ${duration} gi√¢y"
    echo ""
}

# Run
main "$@"
